# PocoFlow

> Orchestration l√©g√®re de workflows LLM.
> Une √©volution renforc√©e de [PocketFlow](https://github.com/The-Pocket/PocketFlow).

Construit avec amour par **Claude & digital-duck** ü¶Ü

---

## Ce que c'est

PocoFlow est un framework minimal pour construire des pipelines LLM sous forme de **graphes orient√©s de
n≈ìuds nano-ETL** communiquant via un Store partag√© et typ√©.

Il conserve la meilleure id√©e de PocketFlow ‚Äî l'abstraction `prep | exec | post` ‚Äî et corrige
les faiblesses qui apparaissent en production :

| Faiblesse | Correction PocoFlow |
|----------|-------------|
| Store dict brut ‚Äî pas de s√©curit√© de type | `Store` avec sch√©ma optionnel + `TypeError` sur les √©critures invalides |
| API d'ar√™tes `>>` ambigu√´ | API unique claire : `.then("action", next_node)` |
| Pas de support async int√©gr√© | `AsyncNode.exec_async()` ‚Äî le framework g√®re `asyncio.run()` |
| Pas d'observabilit√© | Syst√®me de hooks : `node_start / node_end / node_error / flow_end` |
| Pas de point de contr√¥le | Snapshots JSON + **backend SQLite** avec journal d'√©v√©nements complet |
| Pas de support long-running | `run_background()` ‚Üí `RunHandle` avec status, wait, cancel |
| Logging incoh√©rent | Int√©gration **dd-logging** ‚Äî structur√©, sauvegard√© en fichier, avec namespace |
| Pas de visibilit√© de workflow | **UI de monitoring Streamlit** ‚Äî table des ex√©cutions en direct, timeline, inspecteur de store |

**D√©pendances :** [pocketflow](https://github.com/The-Pocket/PocketFlow) + [dd-logging](https://github.com/digital-duck/dd-logging)

---

## Installation

```bash
# Core
pip install pocoflow

# Avec UI de monitoring Streamlit
pip install "pocoflow[ui]"

# D√©veloppement local (depuis le monorepo digital-duck)
pip install -e ~/projects/digital-duck/dd-logging
pip install -e ~/projects/digital-duck/pocoflow"[ui,dev]"
```

---

## D√©marrage rapide

```python
from pocoflow import Node, Flow, Store

class SummariseNode(Node):
    def prep(self, store):
        return store["document"]

    def exec(self, text):
        return llm.summarise(text)          # votre appel LLM ici

    def post(self, store, prep, summary):
        store["summary"] = summary
        return "done"

store = Store({"document": "...", "summary": ""})
Flow(start=SummariseNode(), db_path="pocoflow.db", flow_name="summarise").run(store)
print(store["summary"])
```

Puis ouvrez le moniteur :

```bash
streamlit run pocoflow/ui/monitor.py -- pocoflow.db
```

---

## Concepts de base

### Node ‚Äî nano-ETL

Chaque n≈ìud est une unit√© de traitement en trois phases qui correspond directement √† **Extract ‚Üí Transform ‚Üí Load** :

```
prep(store)              ‚Üí Extract:   lit ce dont ce n≈ìud a besoin depuis le store
exec(prep_result)        ‚Üí Transform: fait le travail (pur ‚Äî pas d'effets de bord sur le store)
post(store, prep, exec)  ‚Üí Load:      √©crit les r√©sultats, retourne la cha√Æne d'action suivante
```

| Phase | √âtape ETL | Puret√© |
|-------|----------|--------|
| `prep` | Extract | lit le store |
| `exec` | Transform | fonction pure ‚Äî r√©essayable, testable sans store |
| `post` | Load + Route | √©crit dans le store, retourne une cha√Æne d'action |

```python
from pocoflow import Node

class CallLLMNode(Node):
    max_retries = 3       # r√©essaie exec() automatiquement en cas d'√©chec
    retry_delay = 1.0     # secondes entre les r√©essais

    def prep(self, store):
        return store["prompt"]

    def exec(self, prompt):
        return llm.call(prompt)   # r√©essay√© jusqu'√† 3√ó en cas d'exception

    def post(self, store, prep, response):
        store["response"] = response
        return "done"
```

### Store ‚Äî √©tat partag√© typ√©

```python
from pocoflow import Store

store = Store(
    data={"query": "", "result": ""},
    schema={"query": str, "result": str},   # v√©rifi√© √† chaque √©criture
    name="my_pipeline",
)
store["query"] = "explain quantum entanglement"
store["query"] = 42          # ‚Üê l√®ve TypeError imm√©diatement

# Observer : d√©clench√© √† chaque √©criture (logging, tracing, mises √† jour UI)
store.add_observer(lambda key, old, new: print(f"{key}: {old!r} ‚Üí {new!r}"))

# Snapshot / restauration JSON (sauvegarde l√©g√®re)
store.snapshot("/tmp/run_42/step_002.json")
store2 = Store.restore("/tmp/run_42/step_002.json")
```

### Flow ‚Äî graphe orient√© avec hooks

```python
from pocoflow import Flow, Store

# C√¢ble les n≈ìuds avec des ar√™tes nomm√©es non ambigu√´s
a.then("ok",    b)
a.then("error", c)
a.then("*",     fallback)   # wildcard : correspond √† toute action non g√©r√©e

# Construit avec persistance SQLite
flow = Flow(
    start=a,
    flow_name="my_pipeline",    # label affich√© dans l'UI de monitoring
    db_path="pocoflow.db",      # SQLite : runs, √©v√©nements, checkpoints
    checkpoint_dir="/tmp/ckpt", # √©crit aussi des snapshots JSON (optionnel)
    max_steps=50,               # protection contre les boucles infinies
)

# Hooks ‚Äî connectez √† n'importe quel logger, sink de m√©triques, ou barre de progression
flow.on("node_start", lambda name, store: print(f"‚ñ∂ {name}"))
flow.on("node_end",   lambda name, action, elapsed, store:
                          print(f"‚úì {name} ‚Üí {action}  ({elapsed:.2f}s)"))
flow.on("node_error", lambda name, exc, store: alert(name, exc))
flow.on("flow_end",   lambda steps, store: print(f"Termin√© en {steps} √©tapes"))

store = Store({"query": "..."})
flow.run(store)
```

### AsyncNode ‚Äî sous-t√¢ches parall√®les

```python
from pocoflow import AsyncNode
import asyncio

class FetchNode(AsyncNode):
    def prep(self, store):
        return store["urls"]

    async def exec_async(self, urls):
        return await asyncio.gather(*[fetch(u) for u in urls])

    def post(self, store, prep, results):
        store["pages"] = results
        return "done"
```

Impl√©mentez `exec_async()` ‚Äî le framework l'appelle via `asyncio.run()`.
Utilisez `asyncio.gather()` √† l'int√©rieur pour de vraies sous-t√¢ches parall√®les.

---

## Backend SQLite

Quand `db_path` est d√©fini, chaque ex√©cution est enti√®rement enregistr√©e dans une base de donn√©es SQLite :

```
pf_runs        ‚Äî une ligne par ex√©cution de flow (run_id, status, timing, error)
pf_checkpoints ‚Äî Snapshot du Store apr√®s chaque n≈ìud (restaurable √† n'importe quelle √©tape)
pf_events      ‚Äî journal d'√©v√©nements ordonn√© (flow_start ‚Üí node_start/end/error ‚Üí flow_end)
```

```python
from pocoflow import WorkflowDB

db = WorkflowDB("pocoflow.db")

# Liste toutes les ex√©cutions
for run in db.list_runs():
    print(run["run_id"], run["status"], run["total_steps"])

# Inspecte les √©v√©nements d'une ex√©cution
for event in db.get_events("my_pipeline-3f9a1b2c"):
    print(event["event"], event["node_name"], event["elapsed_ms"])

# Restaure le Store depuis n'importe quel checkpoint
store = db.load_checkpoint("my_pipeline-3f9a1b2c", step=2)
```

Le mode WAL est activ√© pour que le moniteur Streamlit puisse interroger pendant qu'un flow s'ex√©cute.

---

## Workflows long-running

Pour les flows qui prennent des minutes ou des heures, utilisez `run_background()` pour √©viter le blocage :

```python
flow = Flow(start=my_node, db_path="pocoflow.db", flow_name="research")

# Retourne imm√©diatement ‚Äî le flow s'ex√©cute dans un thread daemon
handle = flow.run_background(store)

print(handle.run_id)          # ex. "research-3f9a1b2c"
print(handle.status)          # "running"   (lit en direct depuis SQLite)

# Bloque jusqu'√† la fin (timeout optionnel)
result = handle.wait(timeout=300)
print(handle.status)          # "completed"

# Annulation coop√©rative ‚Äî s'arr√™te entre les n≈ìuds
handle.cancel()
```

### Reprise apr√®s crash

```python
from pocoflow import WorkflowDB, Flow

db = WorkflowDB("pocoflow.db")

# Trouve l'ex√©cution √©chou√©e
runs = [r for r in db.list_runs() if r["status"] == "failed"]
failed = runs[0]

# Restaure le store depuis le dernier checkpoint r√©ussi
checkpoints = db.get_checkpoints(failed["run_id"])
last = checkpoints[-1]
store = db.load_checkpoint(failed["run_id"], step=last["step"])

# Reprend depuis le n≈ìud apr√®s le dernier checkpoint
flow = Flow(start=my_flow_start, db_path="pocoflow.db")
flow.run(store, resume_from=node_after_crash)
```

---

## UI de monitoring Streamlit

Visualisez et g√©rez toutes les ex√©cutions de workflow depuis un navigateur.

**Autonome :**
```bash
streamlit run pocoflow/ui/monitor.py -- pocoflow.db
```

**Int√©gr√© dans n'importe quelle page Streamlit :**
```python
from pocoflow.ui.monitor import render_workflow_monitor

render_workflow_monitor("pocoflow.db")
```

Fonctionnalit√©s :
- **Table des ex√©cutions** ‚Äî ID d'ex√©cution, nom du flow, badge de statut (‚úÖ üîÑ ‚ùå), heure de d√©but, dur√©e, nombre d'√©tapes
- **Auto-refresh** ‚Äî activez avec des intervalles de 5 / 10 / 30 s ; mises √† jour en direct pendant l'ex√©cution des flows
- **Onglet Timeline** ‚Äî journal d'√©v√©nements ordonn√© par ex√©cution : noms de n≈ìuds, actions, latence par n≈ìud (ms), erreurs
- **Onglet Store Inspector** ‚Äî curseur d'√©tape pour voir l'√©tat du Store √† n'importe quel checkpoint sous forme de table cl√©/valeur + JSON brut
- **Onglet Resume** ‚Äî g√©n√®re un extrait de code Python pr√™t √† coller pour reprendre depuis le checkpoint s√©lectionn√©

---

## Logging

PocoFlow utilise [dd-logging](https://github.com/digital-duck/dd-logging) pour une sortie de log structur√©e,
avec namespace et sauvegarde en fichier.

```python
from pocoflow.logging import setup_logging, get_logger

# Configurez une fois au d√©marrage de l'application (ex. dans le point d'entr√©e CLI ou Streamlit cache_resource)
log_path = setup_logging("run", log_level="debug", adapter="openrouter")
# ‚Üí logs/run-openrouter-20260217-143022.log

# Dans n'importe quel module
_log = get_logger("nodes.summarise")   # ‚Üí pocoflow.nodes.summarise
_log.info("summarising  len=%d", len(text))
```

Hi√©rarchie des loggers :
```
pocoflow
‚îú‚îÄ‚îÄ pocoflow.store
‚îú‚îÄ‚îÄ pocoflow.node
‚îú‚îÄ‚îÄ pocoflow.flow
‚îú‚îÄ‚îÄ pocoflow.db
‚îî‚îÄ‚îÄ pocoflow.runner
```

---

## Migration depuis PocketFlow

```python
# Avant
from pocketflow import Node, Flow

node_a >> node_b                 # cr√©e une ar√™te "default" ‚Äî cause un UserWarning
node_a - "action" >> node_b      # ar√™te nomm√©e (correct mais incoh√©rent)
shared = {}                      # dict brut ‚Äî pas de s√©curit√© de type

# Apr√®s
from pocoflow import Node, Flow, Store

node_a.then("action", node_b)    # API unique non ambigu√´, toujours
shared = Store(data=shared_dict) # typ√©, observable, avec checkpoints
flow.run(shared)                 # dict brut aussi accept√© pour r√©trocompatibilit√©
```

---

## Structure du projet

```
pocoflow/
  __init__.py      ‚Äî API publique : Store, Node, AsyncNode, Flow, WorkflowDB, RunHandle
  store.py         ‚Äî √©tat partag√© typ√©, observable, avec checkpoints JSON
  node.py          ‚Äî Node (sync) + AsyncNode (async) + retry
  flow.py          ‚Äî ex√©cuteur de graphe orient√© : hooks, checkpoints JSON + SQLite, background
  db.py            ‚Äî WorkflowDB : sch√©ma SQLite, CRUD pour runs / checkpoints / √©v√©nements
  logging.py       ‚Äî wrapper dd-logging (namespace pocoflow.*)
  runner.py        ‚Äî RunHandle : status, wait, cancel
  ui/
    monitor.py     ‚Äî moniteur de workflow Streamlit (autonome + int√©grable)
examples/
  hello.py         ‚Äî flow minimal √† deux n≈ìuds avec hooks
tests/
  test_pocoflow.py ‚Äî 25 tests : Store, Node, Flow, WorkflowDB, RunHandle
docs/
  design.md        ‚Äî architecture, d√©cisions de conception, guide de migration
```

---

## Comparaison avec PocketFlow

| Fonctionnalit√© | PocketFlow | PocoFlow v0.2 |
|---------|-----------|--------------|
| Taille du core | ~100 lignes | ~600 lignes |
| √âtat partag√© | dict brut | `Store` typ√© avec sch√©ma |
| API d'ar√™tes | `>>` et `- "action" >>` (confus) | `.then("action", node)` uniquement |
| N≈ìuds async | `asyncio.run()` manuel par n≈ìud | `AsyncNode.exec_async()` |
| Observabilit√© | aucune | syst√®me de hooks √† 4 √©v√©nements |
| Checkpointing | aucun | JSON + SQLite (`WorkflowDB`) |
| Journal d'√©v√©nements | aucun | table `pf_events` ‚Äî piste d'audit compl√®te |
| Long-running | aucun | `run_background()` ‚Üí `RunHandle` |
| Retry | aucun | `max_retries` + `retry_delay` sur n'importe quel Node |
| Ar√™tes wildcard | aucune | `.then("*", fallback)` |
| Logging | manuel | dd-logging (namespace `pocoflow.*`) |
| UI de monitoring | aucune | Moniteur Streamlit avec auto-refresh |
| D√©pendances externes | 0 | pocketflow + dd-logging (toutes deux stdlib uniquement) |

---

## Relation avec PocketFlow

PocoFlow est spirituellement un enfant de PocketFlow.