# PocoFlow

> Orquestaci√≥n ligera de flujos de trabajo LLM.
> Una evoluci√≥n robusta de [PocketFlow](https://github.com/The-Pocket/PocketFlow).

Construido con amor por **Claude & digital-duck** ü¶Ü

---

## Qu√© es

PocoFlow es un framework minimalista para construir pipelines de LLM como **grafos dirigidos de
nodos nano-ETL** que se comunican a trav√©s de un Store compartido y tipado.

Mantiene la mejor idea de PocketFlow ‚Äî la abstracci√≥n `prep | exec | post` ‚Äî y corrige
las debilidades que surgen en producci√≥n:

| Debilidad | Soluci√≥n de PocoFlow |
|----------|-------------|
| Store de dict crudo ‚Äî sin seguridad de tipos | `Store` con esquema opcional + `TypeError` en escrituras incorrectas |
| API de aristas `>>` ambigua | API √∫nica y clara: `.then("action", next_node)` |
| Sin soporte async integrado | `AsyncNode.exec_async()` ‚Äî el framework maneja `asyncio.run()` |
| Sin observabilidad | Sistema de hooks: `node_start / node_end / node_error / flow_end` |
| Sin checkpointing | Snapshots JSON + **backend SQLite** con log de eventos completo |
| Sin soporte de ejecuci√≥n prolongada | `run_background()` ‚Üí `RunHandle` con estado, wait, cancel |
| Logging inconsistente | Integraci√≥n **dd-logging** ‚Äî estructurado, respaldado por archivos, con espacios de nombres |
| Sin visibilidad de flujos de trabajo | **UI monitor Streamlit** ‚Äî tabla de ejecuciones en vivo, timeline, inspector de store |

**Dependencias:** [pocketflow](https://github.com/The-Pocket/PocketFlow) + [dd-logging](https://github.com/digital-duck/dd-logging)

---

## Instalaci√≥n

```bash
# Core
pip install pocoflow

# Con UI monitor Streamlit
pip install "pocoflow[ui]"

# Desarrollo local (desde el monorepo digital-duck)
pip install -e ~/projects/digital-duck/dd-logging
pip install -e ~/projects/digital-duck/pocoflow"[ui,dev]"
```

---

## Inicio R√°pido

```python
from pocoflow import Node, Flow, Store

class SummariseNode(Node):
    def prep(self, store):
        return store["document"]

    def exec(self, text):
        return llm.summarise(text)          # tu llamada LLM aqu√≠

    def post(self, store, prep, summary):
        store["summary"] = summary
        return "done"

store = Store({"document": "...", "summary": ""})
Flow(start=SummariseNode(), db_path="pocoflow.db", flow_name="summarise").run(store)
print(store["summary"])
```

Luego abre el monitor:

```bash
streamlit run pocoflow/ui/monitor.py -- pocoflow.db
```

---

## Conceptos Centrales

### Node ‚Äî nano-ETL

Cada nodo es una unidad de procesamiento de tres fases que mapea directamente a **Extract ‚Üí Transform ‚Üí Load**:

```
prep(store)              ‚Üí Extract:   lee lo que este nodo necesita del store
exec(prep_result)        ‚Üí Transform: hace el trabajo (puro ‚Äî sin efectos secundarios en el store)
post(store, prep, exec)  ‚Üí Load:      escribe resultados de vuelta, devuelve string de acci√≥n siguiente
```

| Fase | Paso ETL | Pureza |
|-------|----------|--------|
| `prep` | Extract | lee el store |
| `exec` | Transform | funci√≥n pura ‚Äî reintentable, testeable sin un store |
| `post` | Load + Route | escribe en el store, devuelve string de acci√≥n |

```python
from pocoflow import Node

class CallLLMNode(Node):
    max_retries = 3       # reintentar exec() autom√°ticamente en fallo
    retry_delay = 1.0     # segundos entre reintentos

    def prep(self, store):
        return store["prompt"]

    def exec(self, prompt):
        return llm.call(prompt)   # reintentado hasta 3√ó en excepci√≥n

    def post(self, store, prep, response):
        store["response"] = response
        return "done"
```

### Store ‚Äî estado compartido tipado

```python
from pocoflow import Store

store = Store(
    data={"query": "", "result": ""},
    schema={"query": str, "result": str},   # verificaci√≥n de tipo en cada escritura
    name="my_pipeline",
)
store["query"] = "explain quantum entanglement"
store["query"] = 42          # ‚Üê lanza TypeError inmediatamente

# Observer: se dispara en cada escritura (logging, tracing, actualizaciones de UI)
store.add_observer(lambda key, old, new: print(f"{key}: {old!r} ‚Üí {new!r}"))

# Snapshot / restauraci√≥n JSON (respaldo ligero)
store.snapshot("/tmp/run_42/step_002.json")
store2 = Store.restore("/tmp/run_42/step_002.json")
```

### Flow ‚Äî grafo dirigido con hooks

```python
from pocoflow import Flow, Store

# Conectar nodos con aristas nombradas sin ambig√ºedad
a.then("ok",    b)
a.then("error", c)
a.then("*",     fallback)   # comod√≠n: coincide con cualquier acci√≥n no manejada

# Construir con persistencia SQLite
flow = Flow(
    start=a,
    flow_name="my_pipeline",    # etiqueta mostrada en la UI monitor
    db_path="pocoflow.db",      # SQLite: ejecuciones, eventos, checkpoints
    checkpoint_dir="/tmp/ckpt", # tambi√©n escribe snapshots JSON (opcional)
    max_steps=50,               # protecci√≥n contra bucles infinitos
)

# Hooks ‚Äî conectar a cualquier logger, sink de m√©tricas o barra de progreso
flow.on("node_start", lambda name, store: print(f"‚ñ∂ {name}"))
flow.on("node_end",   lambda name, action, elapsed, store:
                          print(f"‚úì {name} ‚Üí {action}  ({elapsed:.2f}s)"))
flow.on("node_error", lambda name, exc, store: alert(name, exc))
flow.on("flow_end",   lambda steps, store: print(f"Done in {steps} steps"))

store = Store({"query": "..."})
flow.run(store)
```

### AsyncNode ‚Äî subtareas paralelas

```python
from pocoflow import AsyncNode
import asyncio

class FetchNode(AsyncNode):
    def prep(self, store):
        return store["urls"]

    async def exec_async(self, urls):
        return await asyncio.gather(*[fetch(u) for u in urls])

    def post(self, store, prep, results):
        store["pages"] = results
        return "done"
```

Implementa `exec_async()` ‚Äî el framework lo llama v√≠a `asyncio.run()`.
Usa `asyncio.gather()` dentro para verdaderas subtareas paralelas.

---

## Backend SQLite

Cuando se establece `db_path`, cada ejecuci√≥n se registra completamente en una base de datos SQLite:

```
pf_runs        ‚Äî una fila por ejecuci√≥n de flujo (run_id, estado, timing, error)
pf_checkpoints ‚Äî Snapshot del Store despu√©s de cada nodo (restaurable en cualquier paso)
pf_events      ‚Äî log de eventos ordenado (flow_start ‚Üí node_start/end/error ‚Üí flow_end)
```

```python
from pocoflow import WorkflowDB

db = WorkflowDB("pocoflow.db")

# Listar todas las ejecuciones
for run in db.list_runs():
    print(run["run_id"], run["status"], run["total_steps"])

# Inspeccionar eventos para una ejecuci√≥n
for event in db.get_events("my_pipeline-3f9a1b2c"):
    print(event["event"], event["node_name"], event["elapsed_ms"])

# Restaurar Store desde cualquier checkpoint
store = db.load_checkpoint("my_pipeline-3f9a1b2c", step=2)
```

El modo WAL est√° habilitado para que el monitor Streamlit pueda consultar mientras se ejecuta un flujo.

---

## Flujos de Trabajo de Larga Duraci√≥n

Para flujos que toman minutos u horas, usa `run_background()` para evitar bloqueos:

```python
flow = Flow(start=my_node, db_path="pocoflow.db", flow_name="research")

# Retorna inmediatamente ‚Äî el flujo se ejecuta en un hilo daemon
handle = flow.run_background(store)

print(handle.run_id)          # ej. "research-3f9a1b2c"
print(handle.status)          # "running"   (lee en vivo desde SQLite)

# Bloquear hasta completar (timeout opcional)
result = handle.wait(timeout=300)
print(handle.status)          # "completed"

# Cancelaci√≥n cooperativa ‚Äî se detiene entre nodos
handle.cancel()
```

### Reanudar despu√©s de un fallo

```python
from pocoflow import WorkflowDB, Flow

db = WorkflowDB("pocoflow.db")

# Encontrar la ejecuci√≥n fallida
runs = [r for r in db.list_runs() if r["status"] == "failed"]
failed = runs[0]

# Restaurar store desde el √∫ltimo checkpoint exitoso
checkpoints = db.get_checkpoints(failed["run_id"])
last = checkpoints[-1]
store = db.load_checkpoint(failed["run_id"], step=last["step"])

# Reanudar desde el nodo despu√©s del √∫ltimo checkpoint
flow = Flow(start=my_flow_start, db_path="pocoflow.db")
flow.run(store, resume_from=node_after_crash)
```

---

## UI Monitor Streamlit

Visualiza y gestiona todas las ejecuciones de flujos de trabajo desde un navegador.

**Standalone:**
```bash
streamlit run pocoflow/ui/monitor.py -- pocoflow.db
```

**Embebido en cualquier p√°gina Streamlit:**
```python
from pocoflow.ui.monitor import render_workflow_monitor

render_workflow_monitor("pocoflow.db")
```

Caracter√≠sticas:
- **Tabla de ejecuciones** ‚Äî ID de ejecuci√≥n, nombre del flujo, insignia de estado (‚úÖ üîÑ ‚ùå), hora de inicio, duraci√≥n, conteo de pasos
- **Auto-actualizaci√≥n** ‚Äî activa con intervalos de 5 / 10 / 30 s; actualiza en vivo mientras los flujos se ejecutan
- **Pesta√±a Timeline** ‚Äî log de eventos ordenado por ejecuci√≥n: nombres de nodos, acciones, latencia por nodo (ms), errores
- **Pesta√±a Store Inspector** ‚Äî deslizador de pasos para ver el estado del Store en cualquier checkpoint como tabla clave/valor + JSON crudo
- **Pesta√±a Resume** ‚Äî genera un fragmento de c√≥digo Python listo para pegar para reanudar desde el checkpoint seleccionado

---

## Logging

PocoFlow usa [dd-logging](https://github.com/digital-duck/dd-logging) para salida de log
estructurada, con espacios de nombres y respaldada por archivos.

```python
from pocoflow.logging import setup_logging, get_logger

# Configurar una vez al inicio de la app (ej. en punto de entrada CLI o cache_resource de Streamlit)
log_path = setup_logging("run", log_level="debug", adapter="openrouter")
# ‚Üí logs/run-openrouter-20260217-143022.log

# En cualquier m√≥dulo
_log = get_logger("nodes.summarise")   # ‚Üí pocoflow.nodes.summarise
_log.info("summarising  len=%d", len(text))
```

Jerarqu√≠a de loggers:
```
pocoflow
‚îú‚îÄ‚îÄ pocoflow.store
‚îú‚îÄ‚îÄ pocoflow.node
‚îú‚îÄ‚îÄ pocoflow.flow
‚îú‚îÄ‚îÄ pocoflow.db
‚îî‚îÄ‚îÄ pocoflow.runner
```

---

## Migrando desde PocketFlow

```python
# Antes
from pocketflow import Node, Flow

node_a >> node_b                 # crea arista "default" ‚Äî causa UserWarning
node_a - "action" >> node_b      # arista nombrada (correcto pero inconsistente)
shared = {}                      # dict crudo ‚Äî sin seguridad de tipos

# Despu√©s
from pocoflow import Node, Flow, Store

node_a.then("action", node_b)    # API √∫nica sin ambig√ºedad, siempre
shared = Store(data=shared_dict) # tipado, observable, con checkpoints
flow.run(shared)                 # dict plano tambi√©n aceptado para compatibilidad hacia atr√°s
```

---

## Estructura del Proyecto

```
pocoflow/
  __init__.py      ‚Äî API p√∫blica: Store, Node, AsyncNode, Flow, WorkflowDB, RunHandle
  store.py         ‚Äî estado compartido tipado, observable, con checkpoints JSON
  node.py          ‚Äî Node (sync) + AsyncNode (async) + retry
  flow.py          ‚Äî ejecutor de grafo dirigido: hooks, checkpoints JSON + SQLite, background
  db.py            ‚Äî WorkflowDB: esquema SQLite, CRUD para ejecuciones / checkpoints / eventos
  logging.py       ‚Äî wrapper dd-logging (espacio de nombres pocoflow.*)
  runner.py        ‚Äî RunHandle: estado, wait, cancel
  ui/
    monitor.py     ‚Äî monitor de flujos de trabajo Streamlit (standalone + embebible)
examples/
  hello.py         ‚Äî flujo m√≠nimo de dos nodos con hooks
tests/
  test_pocoflow.py ‚Äî 25 tests: Store, Node, Flow, WorkflowDB, RunHandle
docs/
  design.md        ‚Äî arquitectura, decisiones de dise√±o, gu√≠a de migraci√≥n
```

---

## Comparaci√≥n con PocketFlow

| Caracter√≠stica | PocketFlow | PocoFlow v0.2 |
|---------|-----------|--------------|
| Tama√±o del core | ~100 l√≠neas | ~600 l√≠neas |
| Estado compartido | dict crudo | `Store` tipado con esquema |
| API de aristas | `>>` y `- "action" >>` (confuso) | `.then("action", node)` √∫nicamente |
| Nodos async | `asyncio.run()` manual por nodo | `AsyncNode.exec_async()` |
| Observabilidad | ninguna | sistema de hooks de 4 eventos |
| Checkpointing | ninguno | JSON + SQLite (`WorkflowDB`) |
| Log de eventos | ninguno | tabla `pf_events` ‚Äî pista de auditor√≠a completa |
| Ejecuci√≥n prolongada | ninguna | `run_background()` ‚Üí `RunHandle` |
| Retry | ninguno | `max_retries` + `retry_delay` en cualquier Node |
| Aristas comod√≠n | ninguna | `.then("*", fallback)` |
| Logging | manual | dd-logging (espacio de nombres `pocoflow.*`) |
| UI Monitor | ninguna | Monitor Streamlit con auto-actualizaci√≥n |
| Deps externas | 0 | pocketflow + dd-logging (ambos solo stdlib) |

---

## Relaci√≥n con PocketFlow

PocoFlow es espiritualmente un hijo de PocketFlow. Mantuvimos:
- La abstracci√≥n nano-ETL `prep | exec | post` ‚Äî hermosa y correcta
- Cero dependencia de proveedores ‚Äî trae tu propio cliente LLM
- Sin magia de framework ‚Äî cada comportamiento es rastreable a c√≥digo que puedes leer en minutos

Agregamos lo que los flujos de trabajo LLM en producci√≥n realmente demandan:
- `Store` tipado, observable, con checkpoints
- API de aristas `.then()` sin ambig√ºedad (no m√°s `UserWarning`)
- `AsyncNode` con `exec_async()`